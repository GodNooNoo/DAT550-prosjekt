{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake detection using GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure plots\n",
    "matplotlib.style.use(\"seaborn-poster\")  # Poster = big, paper = small\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "matplotlib.rcParams[\"font.family\"] = \"serif\"\n",
    "sns.set_context(\"poster\")  # Poster = big, paper = small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_set = \"train_set_frames/\"\n",
    "test_set = \"test_set_frames/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64  # 64x64 image size\n",
    "nz = 100  # Size of input vector\n",
    "ndf = 64  # Size of feature map in discriminator\n",
    "ngf = 64  # Size of feature map in generator\n",
    "lr = 0.0002  # Learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.Resize(image_size),\n",
    "        tv.transforms.CenterCrop(image_size),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = tv.datasets.ImageFolder(\n",
    "    root=train_set + \"real\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Use dataloader to get batches\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for the discriminator and generator\n",
    "def init_weights(m):\n",
    "    if type(m) == (torch.nn.ConvTranspose2d or torch.nn.Conv2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif type(m) == torch.nn.BatchNorm2d:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_folder(path):\n",
    "    \"\"\"\n",
    "    Function that predicts the labels of all the images in a folder.\n",
    "    \"\"\"\n",
    "    total = {}\n",
    "    videos = tv.datasets.ImageFolder(\n",
    "        root=path,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    for ind, val in tqdm(videos.class_to_idx.items()):\n",
    "        low = math.inf\n",
    "        high = -1\n",
    "        for i, ele in enumerate(videos.imgs):\n",
    "            _, idx = ele\n",
    "            if idx == val:\n",
    "                if i < low:\n",
    "                    low = i\n",
    "                if i > high:\n",
    "                    high = i\n",
    "        high += 1\n",
    "        video = torch.utils.data.Subset(videos, range(low, high))\n",
    "        results = {}\n",
    "        frame_names = videos.imgs[low:high]\n",
    "        frame_names = [name[0] for name in frame_names]\n",
    "        name_iter = iter(frame_names)\n",
    "        with torch.no_grad():\n",
    "            for i, frame in enumerate(video):\n",
    "                frame_name = next(name_iter)\n",
    "                frame = frame[0]\n",
    "                frame = frame.view(1, *frame.shape)\n",
    "                pred = net_disc(frame).item()\n",
    "                if (\n",
    "                    i != 0 and \"face\" in frame_name and not \"face0\" in frame_name\n",
    "                ):  # If the face is part of a frame with multiple faces, always select the one most likely to be fake.\n",
    "                    frame_name = list(results.keys())[-1]\n",
    "                    results[frame_name] = (\n",
    "                        pred if pred < results[frame_name] else results[frame_name]\n",
    "                    )\n",
    "                else:\n",
    "                    results[frame_name] = pred\n",
    "        values = list(results.values())\n",
    "        total[ind] = round(\n",
    "            np.mean(values)\n",
    "        )  # Classify the video as fake or real based on the majority of the frames.\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        if image_size >= 128:\n",
    "            self.main = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 16),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 8),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 4),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 2),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "                torch.nn.Tanh(),\n",
    "            )\n",
    "        else:\n",
    "            self.main = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 8),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 4),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf * 2),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ngf),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "                torch.nn.Tanh(),\n",
    "            )\n",
    "        self.apply(init_weights)\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "net_gen = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        if image_size >= 128:\n",
    "            self.main = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 2),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 4),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 8),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 16),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "        else:\n",
    "            self.main = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 2),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 4),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "                torch.nn.BatchNorm2d(ndf * 8),\n",
    "                torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "                torch.nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "        self.apply(init_weights)\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "net_disc = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Optiomisers\n",
    "# net_disc.optimiser = torch.optim.Adam(net_disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# net_gen.optimiser = torch.optim.Adam(net_gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_disc = []\n",
    "losses_gen = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        ## Train with real images through discriminator\n",
    "\n",
    "        # Set gradient to 0\n",
    "        net_disc.zero_grad()\n",
    "\n",
    "        batch = batch[0]\n",
    "\n",
    "        # Create tensor with labels for real images\n",
    "        size = batch.size(0)\n",
    "        label = torch.full((size,), 1.0)\n",
    "\n",
    "        # Forward pass batch through discriminator\n",
    "        output = net_disc(batch).view(-1)\n",
    "\n",
    "        # Calculate loss on batch\n",
    "        loss_disc_real = loss_fn(output, label)\n",
    "\n",
    "        # Backwards pass batch t calculate gradient\n",
    "        loss_disc_real.backward()\n",
    "\n",
    "        ## Train with fake images\n",
    "        # Fake batch\n",
    "        batch = torch.randn(size, nz, 1, 1)\n",
    "\n",
    "        # Forward pass fake batch through generator\n",
    "        fake = net_gen(batch)\n",
    "\n",
    "        # Forward pass fake output through discriminator\n",
    "        output = net_disc(fake.detach()).view(-1)\n",
    "\n",
    "        # Calculate discriminator loss on batch\n",
    "        label -= 1\n",
    "        loss_disc_fake = loss_fn(output, label)\n",
    "\n",
    "        # Total loss\n",
    "        loss_disc = loss_disc_real + loss_disc_fake\n",
    "        losses_disc.append(loss_disc.item())\n",
    "\n",
    "        # Backwards pass batch to calculate gradient\n",
    "        loss_disc_fake.backward()\n",
    "\n",
    "        # Update discriminator\n",
    "        net_disc.optimiser.step()\n",
    "\n",
    "        ## Train with fake images through generator\n",
    "        # Set gradient to 0\n",
    "        net_gen.zero_grad()\n",
    "\n",
    "        # Forward pass batch through the updated discriminator.\n",
    "        output = net_disc(fake).view(-1)\n",
    "\n",
    "        # Calculate loss on batch\n",
    "        label += 1\n",
    "        loss_gen = loss_fn(output, label)\n",
    "        losses_gen.append(loss_gen.item())\n",
    "\n",
    "        # Backwards pass batch to calculate gradient\n",
    "        loss_gen.backward()\n",
    "\n",
    "        # Update generator\n",
    "        net_gen.optimiser.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(len(losses_gen)), y=losses_gen, label=\"G\")\n",
    "sns.lineplot(x=range(len(losses_disc)), y=losses_disc, label=\"D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_disc.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real = predict_folder(train_set + \"real\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.DataFrame(train_real.values(), train_real.keys())\n",
    "\n",
    "print(f\"Correctly classified videos: {df_real[0].sum()}\")\n",
    "print(f\"Incorrectly classified videos: {len(df_real.index) - df_real[0].sum()}\")\n",
    "print(\n",
    "    f\"Percentage corretly classified: {round((df_real[0].sum() / len(df_real.index)) * 100, 2)}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake = predict_folder(train_set + \"fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.DataFrame(train_fake.values(), train_fake.keys())\n",
    "\n",
    "print(f\"Correctly classified videos: {len(df_fake) - df_fake[0].sum()}\")\n",
    "print(f\"Incorrectly classified videos: {df_fake[0].sum()}\")\n",
    "print(\n",
    "    f\"Percentage corretly classified: {round(((len(df_fake) - df_fake[0].sum()) / len(df_fake)) * 100, 2)}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_real = predict_folder(test_set + \"real\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.DataFrame(total_real.values(), total_real.keys())\n",
    "\n",
    "print(f\"Correctly classified videos: {df_real[0].sum()}\")\n",
    "print(f\"Incorrectly classified videos: {len(df_real.index) - df_real[0].sum()}\")\n",
    "print(\n",
    "    f\"Percentage corretly classified: {round((df_real[0].sum() / len(df_real.index)) * 100, 2)}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fake = predict_folder(test_set + \"fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.DataFrame(total_fake.values(), total_fake.keys())\n",
    "\n",
    "print(f\"Correctly classified videos: {len(df_fake) - df_fake[0].sum()}\")\n",
    "print(f\"Incorrectly classified videos: {df_fake[0].sum()}\")\n",
    "print(\n",
    "    f\"Percentage corretly classified: {round(((len(df_fake) - df_fake[0].sum()) / len(df_fake)) * 100, 2)}%\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e44d3dbc99e2d349f45ec8bb2a032e2373c7b6a7a829313fa9af53fb21fb918c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
