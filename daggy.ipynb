{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and TF-Hub modules.\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# Some modules to help with reading the dataset.\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "from urllib import request  # requires python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolutional Neural Network.\n",
    "def cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "def train_model(model, epochs=5):\n",
    "\n",
    "    # Create the image generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create the image generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        'sample_set/',  \n",
    "        target_size=(150, 150),\n",
    "        classes=['real', 'fake'],\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        'sample_set/',  \n",
    "        target_size=(150, 150), \n",
    "        classes=['real', 'fake'],\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    # Train the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=Adam(lr=0.001),\n",
    "                    metrics=['accuracy'])\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=25,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=10) \n",
    "    \n",
    "    # Save the model\n",
    "    model.save(\"model.h5\")\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1014 images belonging to 2 classes.\n",
      "Found 1014 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 14s 517ms/step - loss: 0.5572 - accuracy: 0.7823 - val_loss: 0.2686 - val_accuracy: 0.8781\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 13s 512ms/step - loss: 0.0782 - accuracy: 0.9800 - val_loss: 0.0300 - val_accuracy: 0.9875\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 13s 508ms/step - loss: 0.0703 - accuracy: 0.9823 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 13s 498ms/step - loss: 0.0431 - accuracy: 0.9886 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 13s 500ms/step - loss: 0.0344 - accuracy: 0.9924 - val_loss: 0.0077 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model   = cnn_model((150, 150, 3))\n",
    "model   = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, x):\n",
    "        self.filepaths = x.filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1014 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    'sample_set/',  \n",
    "    target_size=(150, 150),\n",
    "    classes=['real', 'fake'],\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "call = VideoCallback(test_generator)\n",
    "\n",
    "pred = model.predict(test_generator, callbacks=[call])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eggbjzxnmg.mp4': 0.5469747,\n",
       " 'eudeqjhdfd.mp4': 0.5826362,\n",
       " 'etohcvnzbj.mp4': 0.5760956,\n",
       " 'eukvucdetx.mp4': 0.62330043}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vidoes = defaultdict(list)\n",
    "for i, path in enumerate(call.filepaths):\n",
    "    vid = path.split(\"\\\\\")[1]\n",
    "    vidoes[vid].append(i)\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "for vid in vidoes:\n",
    "    predictions[vid] = np.mean(pred[vidoes[vid]])\n",
    "    \n",
    "predictions\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
