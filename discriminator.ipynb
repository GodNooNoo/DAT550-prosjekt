{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake detection using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling seeds to control reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"sample_set/real\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 15\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = tv.datasets.ImageFolder(\n",
    "    root=dataroot,\n",
    "    transform=tv.transforms.Compose(\n",
    "        [\n",
    "            tv.transforms.Resize(image_size),\n",
    "            tv.transforms.CenterCrop(image_size),\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=workers\n",
    ")\n",
    "\n",
    "\n",
    "datasetfake = tv.datasets.ImageFolder(\n",
    "    root=\"sample_set/fake\",\n",
    "    transform=tv.transforms.Compose(\n",
    "        [\n",
    "            tv.transforms.Resize(image_size),\n",
    "            tv.transforms.CenterCrop(image_size),\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataloaderfake = torch.utils.data.DataLoader(\n",
    "    datasetfake, batch_size=batch_size, shuffle=True, num_workers=workers\n",
    ")\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = torch.nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            torch.nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            torch.nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(ndf * 2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            torch.nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(ndf * 4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            torch.nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(ndf * 8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            torch.nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = torch.nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for D\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0.0][(0, 4)]\tLoss_D: (3, 4)\tD(x): 0.1671\tD(G(z)): 0.31745728850364685\n",
      "[0.06666666666666667][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9972\tD(G(z)): 0.00181625597178936\n",
      "[0.13333333333333333][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9996\tD(G(z)): 0.00039834066410548985\n",
      "[0.2][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9997\tD(G(z)): 0.0002945365267805755\n",
      "[0.26666666666666666][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9997\tD(G(z)): 0.0003418669512029737\n",
      "[0.3333333333333333][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9998\tD(G(z)): 0.0001977791980607435\n",
      "[0.4][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00018811773043125868\n",
      "[0.4666666666666667][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00020387204131111503\n",
      "[0.5333333333333333][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00028383772587403655\n",
      "[0.6][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00015184268704615533\n",
      "[0.6666666666666666][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00011443744733696803\n",
      "[0.7333333333333333][(0, 4)]\tLoss_D: (0, 4)\tD(x): 1.0\tD(G(z)): 7.145185372792184e-05\n",
      "[0.8][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00012230950233060867\n",
      "[0.8666666666666667][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00011677290603984147\n",
      "[0.9333333333333333][(0, 4)]\tLoss_D: (0, 4)\tD(x): 0.9999\tD(G(z)): 0.00011895198986167088\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "D_losses = []\n",
    "# For each epoch\n",
    "for epoch in tqdm(num_epochs):\n",
    "    itfake = iter(dataloaderfake)\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        fake_cpu = next(itfake)[0].to(device)\n",
    "        b_size = fake_cpu.size(0)\n",
    "        label = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake_cpu).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        D_losses.append(errD.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Discriminator Loss During Training\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_folder(path):\n",
    "    videos = tv.datasets.ImageFolder(\n",
    "        root=path,\n",
    "        transform=tv.transforms.Compose(\n",
    "            [\n",
    "                tv.transforms.Resize(image_size),\n",
    "                tv.transforms.CenterCrop(image_size),\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for ind, val in videos.class_to_idx.items():\n",
    "        low = math.inf\n",
    "        high = -1\n",
    "        for i, ele in enumerate(videos.imgs):\n",
    "            _, idx = ele\n",
    "            if idx == val:\n",
    "                if i < low:\n",
    "                    low = i\n",
    "                if i > high:\n",
    "                    high = i\n",
    "        video = torch.utils.data.Subset(videos, range(low, high))\n",
    "        results = []\n",
    "        for frame in video:\n",
    "            frame = frame[0]\n",
    "            frame = frame.view(1, *frame.shape)\n",
    "            results.append(netD(frame).view(-1).item())\n",
    "        print(ind, np.mean(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eggbjzxnmg.mp4 0.993619021166254\n",
      "eudeqjhdfd.mp4 0.991337468781447\n"
     ]
    }
   ],
   "source": [
    "predict_folder('sample_set/real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etohcvnzbj.mp4 0.009484085282696298\n",
      "eukvucdetx.mp4 0.0019102661750098103\n"
     ]
    }
   ],
   "source": [
    "predict_folder('sample_set/fake')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e44d3dbc99e2d349f45ec8bb2a032e2373c7b6a7a829313fa9af53fb21fb918c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
